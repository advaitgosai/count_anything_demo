{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42978e5-0583-4489-95e2-e319e5567a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_discount_var import kDISCount\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef68b5-4f1c-4ab8-bcb7-b02f25acdf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'clip-ViT-L-14'\n",
    "model = SentenceTransformer(model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ccb0f-501d-4b78-a967-70e127a2fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_probs(query, temperature):\n",
    "    query_emb = model.encode([query], convert_to_tensor=True, show_progress_bar=False)\n",
    "    cos_sims = util.cos_sim(img_emb, query_emb) / temperature\n",
    "    probabilities = np.array(F.softmax(cos_sims, dim=0).cpu().numpy().flatten())\n",
    "    return probabilities\n",
    "\n",
    "def generate_gt(label, type_of_query):\n",
    "    if type_of_query == 'direct':\n",
    "        img_emb = torch.load(f'{model_name}_CUB.pt').to(\"cuda\")\n",
    "        num_images = len(img_emb)\n",
    "        with open('img_names.pkl', 'rb') as f:\n",
    "            img_names = pickle.load(f)\n",
    "        \n",
    "        f = np.zeros(num_images)\n",
    "        \n",
    "        bird_type = label\n",
    "        \n",
    "        for i, img in enumerate(img_names):\n",
    "            if bird_type in img: f[i] = 1\n",
    "        print(f'Positives: {sum(f)}')\n",
    "        return f, img_emb, num_images\n",
    "        \n",
    "    elif type_of_query == 'attribute':\n",
    "        img_emb = torch.load(f'{model_name}_CUB_F.pt').to(\"cuda\")\n",
    "        num_images = len(img_emb)\n",
    "        attributes_path = 'attributes.txt'\n",
    "        entries_path = 'image_attribute_labels.txt'\n",
    "\n",
    "        attribute_name = label\n",
    "\n",
    "        attribute_number = []\n",
    "        with open(attributes_path, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                if attribute_name in parts[1]:\n",
    "                    attribute_number.append(int(parts[0]))\n",
    "\n",
    "        if attribute_number is None:\n",
    "            raise ValueError(f\"Attribute '{attribute_name}' not found\")\n",
    "\n",
    "        print(f'Attribute Number(s): {attribute_number}')\n",
    "\n",
    "        image_indices = set()\n",
    "        with open(entries_path, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split()\n",
    "                image_number, attr_num, value = int(parts[0]), int(parts[1]), int(parts[2])\n",
    "                if attr_num in attribute_number and value == 1:\n",
    "                    image_indices.add(image_number - 1)\n",
    "\n",
    "        idx = list(image_indices)\n",
    "        f = np.zeros(num_images)\n",
    "        f[idx] = 1\n",
    "        print(f'Positives: {sum(f)}')\n",
    "        return f, img_emb, num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dded2d-3555-4037-a03a-3ff4a1c379c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'A photo of a Horned Lark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9adbb3-e10b-4478-a400-47296ad0f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ground truth generation - ONLY if the query is an attribute\n",
    "# label = 'has_primary_color::yellow'\n",
    "# type_of_query = 'attribute'\n",
    "\n",
    "# # Ground truth generation - ONLY if the query is a species (class)\n",
    "label = 'Horned_Lark'\n",
    "type_of_query = 'direct'\n",
    "\n",
    "f, img_emb, num_images = generate_gt(label, type_of_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142b49c-e79e-4fd3-91d5-ae3be4fedc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    X_predict,\n",
    "    y_predict,\n",
    "    n_epochs=10,\n",
    "    weight_decay=1e-1,\n",
    "    lr=1.0e-2,\n",
    "):\n",
    "    x_train = torch.tensor(x_train).float().cuda()\n",
    "    y_train = torch.tensor(y_train).long().cuda()\n",
    "    X_predict = torch.tensor(X_predict).float().cuda()\n",
    "    y_predict = torch.tensor(y_predict).long().cuda()\n",
    "\n",
    "    d = x_train.shape[1]\n",
    "    model = nn.Linear(d, 2).cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay, lr=lr)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            with torch.no_grad():\n",
    "                predicted_classes = torch.argmax(outputs, dim=1)\n",
    "                precision = precision_score(y_train.cpu(), predicted_classes.cpu(), zero_division=0)\n",
    "                recall = recall_score(y_train.cpu(), predicted_classes.cpu())\n",
    "                # print(f\"Epoch {epoch + 1}: Precision = {precision:.4f}, Recall = {recall:.4f} (on test)\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_predict)\n",
    "        predicted_classes = torch.argmax(outputs, dim=1)\n",
    "        probs = nn.functional.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "    # cm = confusion_matrix(y_predict.cpu().numpy(), predicted_classes.cpu().numpy())\n",
    "    return probs\n",
    "\n",
    "def sufficient_samples(labels, minimum_count=2):\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    label_counts = dict(zip(unique, counts))\n",
    "    # Check if both classes have at least minimum_count instances\n",
    "    return all(count >= minimum_count for count in label_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da885e22-c82e-4288-893c-43fa3665fe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "eps = 1e-4\n",
    "temperatures = np.array([0.1])\n",
    "reg = 0.001 if type_of_query == 'direct' else 0.1  # Regularization term for the linear classifier\n",
    "weights = 'var' if type_of_query == 'direct' else 'split'\n",
    "split_values = np.array([0.1, 0.5, 0.9])\n",
    "n_values = np.arange(200, 501, 100)\n",
    "repetitions = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6559f-abff-4e4f-b7c4-905792d95264",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(f)\n",
    "ground_truth = sum(f)\n",
    "\n",
    "# Uniform\n",
    "g_uni = np.full(num_images, 1 / num_images)\n",
    "\n",
    "# Initialize data structures to store results\n",
    "mean_percentage_errors = {temp: [] for temp in temperatures}\n",
    "mean_percentage_error_lower_bounds = {temp: [] for temp in temperatures}\n",
    "mean_percentage_error_upper_bounds = {temp: [] for temp in temperatures}\n",
    "\n",
    "# Adaptive estimator results initialized for each temperature\n",
    "AS_results = {\n",
    "    split: {\n",
    "        temp: {\n",
    "            'mean_percentage_errors_AS': [],\n",
    "            'mean_percentage_error_lower_bounds_AS': [],\n",
    "            'mean_percentage_error_upper_bounds_AS': [],\n",
    "        } for temp in temperatures\n",
    "    } for split in split_values\n",
    "}\n",
    "\n",
    "# Uniform estimator results\n",
    "mean_percentage_errors_UNI = []\n",
    "mean_percentage_error_lower_bounds_UNI = []\n",
    "mean_percentage_error_upper_bounds_UNI = []\n",
    "\n",
    "for n in n_values:\n",
    "    print(f'Processing n={n}')\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        \n",
    "        # DISCount setup for current temperature\n",
    "        percentage_errors_temp = []\n",
    "        percentage_error_lower_bounds_temp = []\n",
    "        percentage_error_upper_bounds_temp = []\n",
    "\n",
    "        # Repeat for uniform estimator\n",
    "        percentage_errors_UNI_temp = []\n",
    "        percentage_error_lower_bounds_UNI_temp = []\n",
    "        percentage_error_upper_bounds_UNI_temp = []\n",
    "    \n",
    "        g = generate_probs(query, temp)  # Generate probability distribution for current temperature\n",
    "    \n",
    "        for split in split_values:\n",
    "\n",
    "            # Adaptive Sampling setup for current temperature\n",
    "            percentage_errors_AS_temp = []\n",
    "            percentage_error_lower_bounds_AS_temp = []\n",
    "            percentage_error_upper_bounds_AS_temp = []\n",
    "        \n",
    "            for _ in tqdm.tqdm(range(repetitions), desc=f'AS: Temperature {temp}, Split {split}'):\n",
    "                \n",
    "                n_split = int(n*split)\n",
    "                        \n",
    "                estimator_AS = kDISCount(g, g, eps)  # Use temperature-based proposal for AS\n",
    "                samples_as = estimator_AS.sample(n=n_split)\n",
    "                screened_samples_as = [f[i] for i in samples_as]\n",
    "                if not sufficient_samples(screened_samples_as): \n",
    "                    # print('Insufficient Positive/Negative Samples, skipping')\n",
    "                    continue\n",
    "                estimator_AS.load(screened_samples_as)\n",
    "                F_hat_temp, CI_temp, Var_hat_temp = estimator_AS.estimate([[i for i, _ in enumerate(g)]])\n",
    "                estimate_pre = F_hat_temp[0]\n",
    "                variance_pre = Var_hat_temp[0]\n",
    "                \n",
    "                X_train = img_emb[samples_as]\n",
    "                y_train = np.array(f[samples_as])\n",
    "\n",
    "                all_indices = np.arange(len(g))\n",
    "                unscreend_indices = np.setdiff1d(all_indices, samples_as)\n",
    "                X_predict = img_emb[unscreend_indices]\n",
    "                y_predict = f[unscreend_indices]\n",
    "\n",
    "                all_indices = np.arange(len(g))\n",
    "                unscreend_indices = np.setdiff1d(all_indices, samples_as)\n",
    "\n",
    "                # Get predictions (probabilities)\n",
    "                predictions_unscreend = train_logreg(X_train, y_train, X_predict, y_predict, weight_decay=reg, n_epochs=1000)\n",
    "          \n",
    "                # Continue with the modified predictions\n",
    "                new_g = np.array([None] * len(g))\n",
    "                for idx, actual_value in zip(samples_as, screened_samples_as):\n",
    "                    new_g[idx] = actual_value\n",
    "                for idx, pred_value in zip(unscreend_indices, predictions_unscreend):\n",
    "                    new_g[idx] = pred_value\n",
    "                    \n",
    "                new_g = (new_g).astype(float)\n",
    "                new_g += eps\n",
    "                norm = new_g.sum()\n",
    "                new_g = new_g/norm\n",
    "    \n",
    "                estimator_linear = kDISCount(new_g, new_g, eps)\n",
    "                n_linear = n - n_split\n",
    "                samples_linear = estimator_linear.sample(n = n_linear)\n",
    "                screened_samples_linear = [f[i] for i in samples_linear]\n",
    "                estimator_linear.load(screened_samples_linear)\n",
    "                F_hat_temp, CI_temp, Var_hat_temp = estimator_linear.estimate([[i for i, _ in enumerate(new_g)]])\n",
    "                estimate_post = F_hat_temp[0]\n",
    "                variance_post = Var_hat_temp[0]\n",
    "                \n",
    "                if weights == 'var':\n",
    "                    # Variance based weights\n",
    "                    weight1 = 1 / variance_pre\n",
    "                    weight2 = 1 / variance_post\n",
    "                    estimate_weighted = (weight1 * estimate_pre + weight2 * estimate_post) / (weight1 + weight2)  \n",
    "        \n",
    "                elif weights == 'split':\n",
    "                    # Sample-ratio based weights (pick one)\n",
    "                    estimate_weighted = split*estimate_pre + (1-split)*estimate_post\n",
    "                \n",
    "                perc_error_AS = abs(estimate_weighted - ground_truth) / ground_truth * 100\n",
    "                perc_error_lb_AS = abs(estimate_weighted - CI_temp[0] - ground_truth) / ground_truth * 100\n",
    "                perc_error_ub_AS = abs(estimate_weighted + CI_temp[0] - ground_truth) / ground_truth * 100\n",
    "\n",
    "                percentage_errors_AS_temp.append(perc_error_AS)\n",
    "                percentage_error_lower_bounds_AS_temp.append(perc_error_lb_AS)\n",
    "                percentage_error_upper_bounds_AS_temp.append(perc_error_ub_AS)\n",
    "            \n",
    "            # Store mean errors for AS at current temperature\n",
    "            AS_results[split][temp]['mean_percentage_errors_AS'].append(np.mean(percentage_errors_AS_temp))\n",
    "            AS_results[split][temp]['mean_percentage_error_lower_bounds_AS'].append(np.mean(percentage_error_lower_bounds_AS_temp))\n",
    "            AS_results[split][temp]['mean_percentage_error_upper_bounds_AS'].append(np.mean(percentage_error_upper_bounds_AS_temp))\n",
    "       \n",
    "        \n",
    "        for _ in tqdm.tqdm(range(repetitions), desc=f'DIS: Temperature {temp}'):\n",
    "\n",
    "            estimator_temp = kDISCount(g, g, eps)\n",
    "            samples_temp = estimator_temp.sample(n=n)\n",
    "            screened_samples_temp = [f[i] for i in samples_temp]\n",
    "            estimator_temp.load(screened_samples_temp)\n",
    "            F_hat_temp, CI_temp, Var_hat_temp = estimator_temp.estimate([[i for i, _ in enumerate(g)]])\n",
    "\n",
    "            # Calculate errors for temperature-based estimation\n",
    "            perc_error_temp = abs(F_hat_temp[0] - ground_truth) / ground_truth * 100\n",
    "            perc_error_lb_temp = abs(F_hat_temp[0] - CI_temp[0] - ground_truth) / ground_truth * 100\n",
    "            perc_error_ub_temp = abs(F_hat_temp[0] + CI_temp[0] - ground_truth) / ground_truth * 100\n",
    "\n",
    "            percentage_errors_temp.append(perc_error_temp)\n",
    "            percentage_error_lower_bounds_temp.append(perc_error_lb_temp)\n",
    "            percentage_error_upper_bounds_temp.append(perc_error_ub_temp)\n",
    "\n",
    "        # Store mean errors for current temperature\n",
    "        mean_percentage_errors[temp].append(np.mean(percentage_errors_temp))\n",
    "        mean_percentage_error_lower_bounds[temp].append(np.mean(percentage_error_lower_bounds_temp))\n",
    "        mean_percentage_error_upper_bounds[temp].append(np.mean(percentage_error_upper_bounds_temp))\n",
    "\n",
    "\n",
    "    for _ in tqdm.tqdm(range(repetitions), desc='Uniform'):\n",
    "\n",
    "        estimator_UNI = kDISCount(g_uni, g_uni, eps)\n",
    "        samples_uni = estimator_UNI.sample(n=n)\n",
    "        screened_samples_uni = [f[i] for i in samples_uni]\n",
    "        estimator_UNI.load(screened_samples_uni)\n",
    "        F_hat_uni, CI_uni, Var_hat_uni = estimator_UNI.estimate([[i for i, _ in enumerate(g)]])\n",
    "\n",
    "        perc_error_UNI = abs(F_hat_uni[0] - ground_truth) / ground_truth * 100\n",
    "        perc_error_lb_UNI = abs(F_hat_uni[0] - CI_uni[0] - ground_truth) / ground_truth * 100\n",
    "        perc_error_ub_UNI = abs(F_hat_uni[0] + CI_uni[0] - ground_truth) / ground_truth * 100\n",
    "\n",
    "        percentage_errors_UNI_temp.append(perc_error_UNI)\n",
    "        percentage_error_lower_bounds_UNI_temp.append(perc_error_lb_UNI)\n",
    "        percentage_error_upper_bounds_UNI_temp.append(perc_error_ub_UNI)\n",
    "\n",
    "    # Store mean errors for uniform estimator\n",
    "    mean_percentage_errors_UNI.append(np.mean(percentage_errors_UNI_temp))\n",
    "    mean_percentage_error_lower_bounds_UNI.append(np.mean(percentage_error_lower_bounds_UNI_temp))\n",
    "    mean_percentage_error_upper_bounds_UNI.append(np.mean(percentage_error_upper_bounds_UNI_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f774f8-1dd4-4b00-b35d-e998c1e55ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "ax4 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "num_splits = len(split_values)\n",
    "colors_adaptive = plt.cm.Greens(np.linspace(0.35, 0.75, num_splits))\n",
    "\n",
    "for i, temp in enumerate(temperatures):\n",
    "    ax4.plot(n_values, mean_percentage_errors[temp], label=f'DISCount', color='blue', marker='x', markersize=3, linestyle='-')\n",
    "    \n",
    "ax4.plot(n_values, mean_percentage_errors_UNI, label=f'Uniform', color='orange', marker='x', markersize=3, linestyle='-')\n",
    "\n",
    "# Adaptive plots\n",
    "for i, temp in enumerate(temperatures):\n",
    "    for j, split in enumerate(split_values):\n",
    "        ax4.plot(n_values, AS_results[split][temp]['mean_percentage_errors_AS'], label=f'Adaptive: temp={temp}, split={split}', color=colors_adaptive[j], marker='x', markersize=3, linestyle='-')\n",
    "\n",
    "ax4.set_xlabel('Number of Samples')\n",
    "ax4.set_ylabel('Erorr Rate (%)')\n",
    "ax4.set_title(f\"query: '{query}' on CUB\", fontsize=10)\n",
    "ax4.legend(loc='upper right', fontsize=8)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# # Serialize the figure to a file\n",
    "# with open('{name}.pickle', 'wb') as file:\n",
    "#     pickle.dump(fig, file)\n",
    "\n",
    "plt.show(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:af_cluster]",
   "language": "python",
   "name": "conda-env-af_cluster-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
